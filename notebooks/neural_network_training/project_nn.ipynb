{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loading ICD phenotype matrix, this might take a while\n",
      "WARNING:root:Finished loading ICD10 matrix\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:513: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:521: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:555: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object,\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorflow/python/framework/dtypes.py:565: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool,\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:108: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object:\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py:110: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool:\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorflow/python/ops/numpy_ops/np_random.py:95: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def randint(low, high=None, size=None, dtype=onp.int):  # pylint: disable=missing-function-docstring\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:572: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.object, string),\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:573: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  (np.bool, bool),\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:597: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING: np.object,\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:601: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL: np.bool,\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:618: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_STRING_REF: np.object,\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:623: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  types_pb2.DT_BOOL_REF: np.bool,\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorboard/util/tensor_util.py:113: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.object: SlowAppendObjectArrayToTensorProto,\n",
      "/lab/corradin_biobank/FOR_AN/combinatorial_GWAS/.venv/lib/python3.8/site-packages/tensorboard/util/tensor_util.py:114: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  np.bool: SlowAppendBoolArrayToTensorProto,\n"
     ]
    }
   ],
   "source": [
    "import combinatorial_gwas.high_level as cgwas\n",
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import string\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Constants\n",
    "\n",
    "* A = number of different genotypic alleles\n",
    "* P = number of different phenotypes\n",
    "* D = dropout rate\n",
    "* l2 = L2 regularization rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture\n",
    "Outputs:\n",
    "\n",
    "1. Input: N x A x 3\n",
    "1. Dense Layer w/ ReLU: N x A // 3\n",
    "1. Dropout(D): N x A // 3\n",
    "1. Dense Layer w/ ReLU: N x P * 3\n",
    "1. Dense Layer w/ Sigmoid: N x P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DNN_model(d1, dropout, l2, A, P):\n",
    "    regularizer = tf.keras.regularizers.L2(l2)\n",
    "    return tf.keras.Sequential(layers=[\n",
    "        tf.keras.layers.InputLayer(input_shape=(A, 3)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(d1, activation=tf.nn.relu, kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(P, activation=tf.nn.sigmoid, kernel_regularizer=regularizer)\n",
    "    ], name='nn_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Parameters\n",
    "#### Loss Function\n",
    "Binary Cross-Entropy + L2 Regularization\n",
    "#### Optimizer\n",
    "Adam\n",
    "#### Metric\n",
    "Binary Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, optimizer):\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy', tf.metrics.AUC()])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "epochs = 20\n",
    "use_multiprocessing=False\n",
    "validation_split = 0.2\n",
    "\n",
    "def get_tunable_DNN_model(hp, d1_min, d1_max, d_step, A, P):\n",
    "    d1_units = hp.Int('d1_units', min_value=d1_min, max_value=d1_max, step=d_step)\n",
    "    dropout = hp.Choice('dropout', values=[0.2, 0.5, 0.8])\n",
    "    l2 = hp.Choice('l2', values=[0.01, 0.005, 0.001])\n",
    "    lr = hp.Choice('lr', values=[0.01, 0.005, 0.001])\n",
    "    model = make_DNN_model(d1_units, dropout, l2, A, P)\n",
    "    compile_model(model, tf.keras.optimizers.Adam(lr))\n",
    "    return model\n",
    "\n",
    "def get_tuner(model_builder):\n",
    "    try:\n",
    "      shutil.rmtree('hp_tuning')\n",
    "    except FileNotFoundError:\n",
    "      pass\n",
    "    return kt.Hyperband(model_builder, objective=kt.Objective('val_auc', direction='max'), max_epochs=epochs, executions_per_trial=3, directory='hp_tuning', project_name='initial_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_min = max(P // 4, 1)\n",
    "d1_max = P * 64\n",
    "d_step = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_data(N, A, P):\n",
    " #   genotypes = tf.stack([tf.constant([[1, 0, 0]] * A, dtype=tf.float32)] * N)\n",
    "  #  phenotypes = tf.stack([tf.constant([1] * P, dtype=tf.float32)] * N)\n",
    "   # return genotypes, phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample IDs are read from /lab/corradin_biobank/Raw_UKB_downloads/sample_files/ukb45624_imp_chr21_v3_s487275.sample.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping genotypes: 100%|██████████| 1261158/1261158 [01:09<00:00, 18040.30it/s]\n"
     ]
    }
   ],
   "source": [
    "datasource = cgwas.chromosome_datasource(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading -- time=0:00:00.00, thread 1 of 1, part 1 of 1\n"
     ]
    }
   ],
   "source": [
    "search_data = datasource.get_data(snp_filters=[cgwas.snp_filter('R07', cgwas.snp_filter.SORT_PVALUE)], max_samples=1000)\n",
    "search_train_x, search_validation_x, search_train_y, search_validation_y = sklearn.model_selection.train_test_split(*search_data, test_size=0.2, random_state=0, stratify=search_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 59\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "search_train_x, search_validation_x, search_train_y, search_validation_y = sklearn.model_selection.train_test_split(*search_data, test_size=0.2, random_state=0, stratify=search_data[1])\n",
    "np.set_printoptions(threshold=1000)\n",
    "count = 0\n",
    "for i in range(search_train_x.shape[0]):\n",
    "    for j in range(search_train_x.shape[1]):\n",
    "        if search_train_x[i][j][0] != 1:\n",
    "            count += 1\n",
    "search_train_y = np.array(search_train_y)\n",
    "count2 = 0\n",
    "for i in range(search_train_y.shape[0]):\n",
    "    if search_train_y[i]:\n",
    "        count2 += 1\n",
    "print(count, count2)\n",
    "print(search_train_x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 33s]\n",
      "val_auc: 0.48270271221796673\n",
      "\n",
      "Best val_auc So Far: 0.5331531961758932\n",
      "Total elapsed time: 00h 14m 35s\n",
      "Results summary\n",
      "Results in hp_tuning/initial_model\n",
      "Showing 10 best trials\n",
      "Objective(name='val_auc', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 17\n",
      "dropout: 0.8\n",
      "l2: 0.001\n",
      "lr: 0.001\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 3\n",
      "tuner/bracket: 2\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 6c0de381e3c2b88bbcb0dda6564e6dda\n",
      "Score: 0.5331531961758932\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 33\n",
      "dropout: 0.8\n",
      "l2: 0.001\n",
      "lr: 0.01\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.5302702784538269\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 33\n",
      "dropout: 0.2\n",
      "l2: 0.001\n",
      "lr: 0.01\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.5237837831179301\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 33\n",
      "dropout: 0.5\n",
      "l2: 0.001\n",
      "lr: 0.01\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.5237837831179301\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 17\n",
      "dropout: 0.8\n",
      "l2: 0.01\n",
      "lr: 0.001\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.5115315616130829\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 1\n",
      "dropout: 0.2\n",
      "l2: 0.01\n",
      "lr: 0.005\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 2\n",
      "tuner/round: 2\n",
      "tuner/trial_id: 7651149de3d8d1372f8c81076cb21c10\n",
      "Score: 0.5115315516789755\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 1\n",
      "dropout: 0.2\n",
      "l2: 0.01\n",
      "lr: 0.001\n",
      "tuner/epochs: 20\n",
      "tuner/initial_epoch: 7\n",
      "tuner/bracket: 1\n",
      "tuner/round: 1\n",
      "tuner/trial_id: 720e78d512ce1b6e76714c300bb37ad2\n",
      "Score: 0.5108108520507812\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 1\n",
      "dropout: 0.2\n",
      "l2: 0.01\n",
      "lr: 0.001\n",
      "tuner/epochs: 7\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.5079279243946075\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 1\n",
      "dropout: 0.8\n",
      "l2: 0.01\n",
      "lr: 0.001\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.5072072247664133\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 17\n",
      "dropout: 0.8\n",
      "l2: 0.001\n",
      "lr: 0.001\n",
      "tuner/epochs: 3\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 2\n",
      "tuner/round: 0\n",
      "Score: 0.5057657758394877\n"
     ]
    }
   ],
   "source": [
    "tuner = get_tuner(lambda hp: get_tunable_DNN_model(hp, d1_min, d1_max, d_step, search_train_x.shape[1], search_train_y.shape[1]))\n",
    "tuner.search_space_summary()\n",
    "tuner.search(search_train_x, search_train_y, epochs=epochs, validation_data=(search_validation_x, search_validation_y))\n",
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"nn_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 17)                51017     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 17)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 51,035\n",
      "Trainable params: 51,035\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models = tuner.get_best_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x, y = input_processing.get_data(A, 100000)\n",
    "train_x, validation_x, train_y, validation_y = sklearn.model_selection.train_test_split(x, y, test_size=validation_split, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "800/800 [==============================] - 5s 6ms/step - loss: 0.3695 - accuracy: 0.9627 - auc: 0.5210 - val_loss: 0.1787 - val_accuracy: 0.9622 - val_auc: 0.5146\n",
      "Epoch 2/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.2390 - accuracy: 0.9611 - auc: 0.4999 - val_loss: 0.1668 - val_accuracy: 0.9622 - val_auc: 0.5318\n",
      "Epoch 3/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1965 - accuracy: 0.9630 - auc: 0.5015 - val_loss: 0.1670 - val_accuracy: 0.9622 - val_auc: 0.5043\n",
      "Epoch 4/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1795 - accuracy: 0.9626 - auc: 0.5049 - val_loss: 0.1658 - val_accuracy: 0.9622 - val_auc: 0.5071\n",
      "Epoch 5/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1726 - accuracy: 0.9617 - auc: 0.5025 - val_loss: 0.1653 - val_accuracy: 0.9622 - val_auc: 0.5091\n",
      "Epoch 6/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1662 - accuracy: 0.9620 - auc: 0.5061 - val_loss: 0.1625 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 7/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1624 - accuracy: 0.9621 - auc: 0.5205 - val_loss: 0.1615 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 8/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1598 - accuracy: 0.9627 - auc: 0.4939 - val_loss: 0.1610 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 9/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1611 - accuracy: 0.9622 - auc: 0.4971 - val_loss: 0.1609 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 10/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1626 - accuracy: 0.9617 - auc: 0.5000 - val_loss: 0.1609 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 11/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1587 - accuracy: 0.9629 - auc: 0.5002 - val_loss: 0.1609 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 12/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1613 - accuracy: 0.9621 - auc: 0.4995 - val_loss: 0.1609 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 13/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1583 - accuracy: 0.9631 - auc: 0.5000 - val_loss: 0.1609 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 14/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1636 - accuracy: 0.9615 - auc: 0.5054 - val_loss: 0.1609 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 15/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1574 - accuracy: 0.9633 - auc: 0.4991 - val_loss: 0.1623 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 16/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1617 - accuracy: 0.9621 - auc: 0.4970 - val_loss: 0.1610 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 17/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1597 - accuracy: 0.9626 - auc: 0.5019 - val_loss: 0.1609 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 18/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1602 - accuracy: 0.9625 - auc: 0.5001 - val_loss: 0.1609 - val_accuracy: 0.9622 - val_auc: 0.5000\n",
      "Epoch 19/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1638 - accuracy: 0.9614 - auc: 0.5013 - val_loss: 0.1613 - val_accuracy: 0.9622 - val_auc: 0.4934\n",
      "Epoch 20/20\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.1624 - accuracy: 0.9618 - auc: 0.4993 - val_loss: 0.1609 - val_accuracy: 0.9622 - val_auc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "histories = [model.fit(x=train_x, y=train_y, batch_size=batch_size, epochs=epochs, validation_data=(validation_x, validation_y), use_multiprocessing=use_multiprocessing, workers=os.cpu_count() - 1 if use_multiprocessing else 1) for model in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0628c71d94c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_processing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_multiprocessing\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "test_x, test_y = input_processing.get_data(A, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9760 - auc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model = models[0]\n",
    "history = model.evaluate(x=test_x, y=test_y, use_multiprocessing=use_multiprocessing, workers=os.cpu_count() - 1 if use_multiprocessing else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/6.874 project/Colab/models/dnn/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('/content/gdrive/My Drive/6.874 project/Colab/models/dnn')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
