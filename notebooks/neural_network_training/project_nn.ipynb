{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0486804d988035991fb91a78715f8006ddfa43aadf0cb736030b0d26aa2070e55",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "486804d988035991fb91a78715f8006ddfa43aadf0cb736030b0d26aa2070e55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import kerastuner as kt\n",
    "import os\n",
    "import shutil\n",
    "import string"
   ]
  },
  {
   "source": [
    "## Useful Constants\n",
    "\n",
    "* A = number of different genotypic alleles\n",
    "* P = number of different phenotypes\n",
    "* D = dropout rate\n",
    "* l2 = L2 regularization rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 1\n",
    "P = 1"
   ]
  },
  {
   "source": [
    "## Network Architecture\n",
    "Outputs:\n",
    "\n",
    "1. Input: N x A x 3\n",
    "1. Dense Layer w/ ReLU: N x A // 3\n",
    "1. Dropout(D): N x A // 3\n",
    "1. Dense Layer w/ ReLU: N x P * 3\n",
    "1. Dense Layer w/ Sigmoid: N x P"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DNN_model(d1, dropout, d2, l2):\n",
    "    regularizer = tf.keras.regularizers.L2(l2)\n",
    "    return tf.keras.Sequential(layers=[\n",
    "        tf.keras.layers.InputLayer(input_shape=(A, 3)),\n",
    "        tf.keras.layers.Dense(d1, activation=tf.nn.relu, kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dropout(dropout),\n",
    "        tf.keras.layers.Dense(d2, activation=tf.nn.relu, kernel_regularizer=regularizer),\n",
    "        tf.keras.layers.Dense(P, activation=tf.nn.sigmoid, kernel_regularizer=regularizer)\n",
    "    ], name='nn_model')"
   ]
  },
  {
   "source": [
    "## Model Training Parameters\n",
    "#### Loss Function\n",
    "Binary Cross-Entropy + L2 Regularization\n",
    "#### Optimizer\n",
    "Adam\n",
    "#### Metric\n",
    "Binary Accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_model(model, optimizer):\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "## Hyperparameter Tuning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "epochs = 10\n",
    "use_multiprocessing=True\n",
    "validation_split = 0.2\n",
    "\n",
    "def get_tunable_DNN_model(hp, d1_min, d1_max, d2_min, d2_max, d_step):\n",
    "    d1_units = hp.Int('d1_units', min_value=d1_min, max_value=d1_max, step=d_step)\n",
    "    d2_units = hp.Int('d2_units', min_value=d2_min, max_value=d2_max, step=d_step)\n",
    "    dropout = hp.Choice('dropout', values=[0.2, 0.5, 0.8])\n",
    "    l2 = hp.Choice('l2', values=[0.01, 0.005, 0.001])\n",
    "    lr = hp.Choice('lr', values=[0.01, 0.005, 0.001])\n",
    "    model = make_DNN_model(d1_units, dropout, d2_units, l2)\n",
    "    compile_model(model, tf.keras.optimizers.Adam(lr))\n",
    "    return model\n",
    "\n",
    "def get_tuner(model_builder):\n",
    "    shutil.rmtree('hp_tuning')\n",
    "    return kt.RandomSearch(model_builder, objective='val_accuracy', max_trials=5, executions_per_trial=3, directory='hp_tuning', project_name='initial_model')"
   ]
  },
  {
   "source": [
    "## Search Space"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1_min = max(A // 4, 1)\n",
    "d1_max = A * 2\n",
    "d2_min = P * 2\n",
    "d2_max = P * 4\n",
    "d_step = 1"
   ]
  },
  {
   "source": [
    "## Get Training Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def get_data(N, A, P):\n",
    "    genotypes = tf.stack([tf.constant([[1, 0, 0]] * A, dtype=tf.float32)] * N)\n",
    "    phenotypes = tf.stack([tf.constant([1] * P, dtype=tf.float32)] * N)\n",
    "    return genotypes, phenotypes"
   ]
  },
  {
   "source": [
    "## Hyperparameter Tuning Call"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trial 5 Complete [00h 00m 04s]\n",
      "val_accuracy: 1.0\n",
      "\n",
      "Best val_accuracy So Far: 1.0\n",
      "Total elapsed time: 00h 00m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Results summary\n",
      "Results in hp_tuning\\initial_model\n",
      "Showing 10 best trials\n",
      "Objective(name='val_accuracy', direction='max')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 2\n",
      "d2_units: 2\n",
      "dropout: 0.8\n",
      "l2: 0.001\n",
      "lr: 0.01\n",
      "Score: 1.0\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 1\n",
      "d2_units: 4\n",
      "dropout: 0.5\n",
      "l2: 0.005\n",
      "lr: 0.01\n",
      "Score: 1.0\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 2\n",
      "d2_units: 3\n",
      "dropout: 0.2\n",
      "l2: 0.01\n",
      "lr: 0.001\n",
      "Score: 0.6666666666666666\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 2\n",
      "d2_units: 3\n",
      "dropout: 0.5\n",
      "l2: 0.005\n",
      "lr: 0.01\n",
      "Score: 0.6666666666666666\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "d1_units: 2\n",
      "d2_units: 2\n",
      "dropout: 0.2\n",
      "l2: 0.001\n",
      "lr: 0.001\n",
      "Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "tuner = get_tuner(lambda hp: get_tunable_DNN_model(hp, d1_min, d1_max, d2_min, d2_max, d_step))\n",
    "tuner.search_space_summary()\n",
    "tuner.search(*get_data(10, A, P), epochs=epochs, validation_data=get_data(2, A, P))\n",
    "tuner.results_summary()"
   ]
  },
  {
   "source": [
    "## Optimal Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal = [2, 2, 0.8, 0.001, 0.01]\n",
    "model = make_DNN_model(optimal[0], optimal[2], optimal[1], optimal[3])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(optimal[4]), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "## Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "800/800 [==============================] - 1s 892us/step - loss: 0.1645 - accuracy: 0.9739 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "800/800 [==============================] - 1s 773us/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "800/800 [==============================] - 1s 731us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "800/800 [==============================] - 1s 722us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "800/800 [==============================] - 1s 735us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "800/800 [==============================] - 1s 732us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "800/800 [==============================] - 1s 877us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "800/800 [==============================] - 1s 807us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.6343e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "800/800 [==============================] - 1s 806us/step - loss: 9.0154e-04 - accuracy: 1.0000 - val_loss: 7.0394e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "800/800 [==============================] - 1s 731us/step - loss: 6.5093e-04 - accuracy: 1.0000 - val_loss: 4.9914e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b14f55e940>"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "x, y = get_data(1000, A, P)\n",
    "history = model.fit(x=x, y=y, batch_size=batch_size, epochs=epochs, validation_split=validation_split, use_multiprocessing=use_multiprocessing, workers=os.cpu_count() - 1 if use_multiprocessing else 1)"
   ]
  },
  {
   "source": [
    "## Test Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1/1 [==============================] - 0s 159ms/step - loss: 4.9914e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = get_data(10, A, P)\n",
    "history = model.evaluate(x=test_x, y=test_y, use_multiprocessing=use_multiprocessing, workers=os.cpu_count() - 1 if use_multiprocessing else 1)"
   ]
  }
 ]
}